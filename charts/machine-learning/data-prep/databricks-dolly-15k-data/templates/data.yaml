---
apiVersion: v1
kind: ConfigMap
metadata:
  name: databricks-dolly-15k-{{ .Release.Name }}
data:
  databricks-dolly-15k.sh: |
    #!/bin/bash

    yum install -y wget

    [[ -d $DATA_DIR ]] && echo "$DATA_DIR already exists" && exit 0
    mkdir -p $DATA_DIR
    echo "Data dir: $DATA_DIR"
    
    wget -O $DATA_DIR/data.jsonl https://huggingface.co/datasets/databricks/databricks-dolly-15k/resolve/main/databricks-dolly-15k.jsonl
---
apiVersion: v1
kind: Pod
metadata:
  name: databricks-dolly-15k-{{ .Release.Name }}
  annotations:
    karpenter.sh/do-not-disrupt: "true"
    sidecar.istio.io/inject: 'false'
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
spec:
  restartPolicy: Never
  volumes:
  - name: pv
    persistentVolumeClaim:
      claimName: {{ .Values.pvc.name }} 
  - name: config
    configMap:
      defaultMode: 420
      items:
      - key: databricks-dolly-15k.sh
        mode: 365
        path: databricks-dolly-15k.sh
      name: databricks-dolly-15k-{{ .Release.Name }}
  containers:
  - name: databricks-dolly-15k
    env:
    - name: DATA_DIR 
      value: {{ .Values.pvc.mount_path }}/{{ .Values.pvc.data_path }}
    command:
    -  sh 
    - /etc/config/databricks-dolly-15k.sh
    image: amazonlinux
    imagePullPolicy: IfNotPresent
    volumeMounts:
    - mountPath: /etc/config
      name: config
    - mountPath: {{ .Values.pvc.mount_path }}
      name: pv
    resources:
      requests:
        cpu: "256m"
        memory: "64Mi"
      limits:
        cpu: "1000m"
        memory: "256Mi"

image: '763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training-neuronx:1.13.1-neuronx-py310-sdk2.17.0-ubuntu20.04'
backoff_limit: 2000
ebs:
  storage: 200Gi
  mount_path: /tmp
resources:
  requests:
    "aws.amazon.com/neuron": 16 
    "vpc.amazonaws.com/efa": 8
  limits:
    "aws.amazon.com/neuron": 16 
    "vpc.amazonaws.com/efa": 8
  nnodes: 4
  nproc_per_node: 32 
  node_type: 'trn1.32xlarge' 
tolerations:
  - key: "aws.amazon.com/neuron"
    operator: "Exists"
    effect: "NoSchedule"
git:
  repo_url: "https://github.com/aws-neuron/neuronx-nemo-megatron.git"
  commit: 6038bb80b5ae59d3f4a99ed38a4f68fa0e22665a
  branch: main
pre_script: 
  - pip3 install --upgrade pip
  - ./build.sh && pip3 install ./build/*.whl
  - pip3 install Cython==3.0.9
  - pip3 install -r requirements.txt torch==1.13.1 protobuf==3.20.3
  - 'python3 -c "from nemo.collections.nlp.data.language_modeling.megatron.dataset_utils import compile_helper; compile_helper()"'
  - SCRIPT_DIR=$GIT_CLONE_DIR/nemo/examples/nlp/language_modeling
  - cd $SCRIPT_DIR
  - LOGS_DIR=$LOG_ROOT/$PET_NODE_RANK
  - '[[ -d $LOGS_DIR ]] && rm -rf $LOGS_DIR'
  - mkdir -p $LOGS_DIR 
  - OUTPUT_LOG=$LOGS_DIR/compile.log
  - CACHE_DIR=$CACHE_ROOT/$PET_NODE_RANK
  - '[[ -d $CACHE_DIR ]] && rm -rf $CACHE_DIR'
  - mkdir -p $CACHE_DIR
  - TMP_CACHE_DIR=/tmp/cache
  - DATASET_PATH="$DATA_ROOT/tokenized_text_document"
  - DISTRIBUTED_ARGS="--nproc_per_node $PET_NPROC_PER_NODE --nnodes $PET_NNODES --node_rank $PET_NODE_RANK --master_addr $PET_MASTER_ADDR --master_port $PET_MASTER_PORT"
  - INIT_METHOD_STD=0.021
  - LAYERNORM_EPSILON=1e-5
  - WARMUP_STEPS=10
  - SEQ_LENGTH=2048
  - HS=4096
  - TP=8
  - PP=1
  - N_LAYERS=32
  - N_AH=32
  - UBS=1
  - FFN_HS=11008
  - GBS=256
  - TRAIN_ITERS=3
  - LLAMA2_ARGS="--config-path=conf 
    --config-name=megatron_llama_config 
    trainer.devices=$PET_NPROC_PER_NODE 
    trainer.num_nodes=$PET_NNODES 
    trainer.max_epochs=null 
    trainer.max_steps=$TRAIN_ITERS 
    trainer.val_check_interval=$TRAIN_ITERS 
    trainer.log_every_n_steps=1 
    trainer.limit_val_batches=1 
    trainer.limit_test_batches=1 
    trainer.accumulate_grad_batches=1 
    trainer.precision=32 
    model.megatron_amp_O2=$megatron_amp_O2 
    model.tokenizer.type=$MODEL_PATH 
    model.micro_batch_size=$UBS 
    model.global_batch_size=$GBS 
    model.tensor_model_parallel_size=$TP 
    model.pipeline_model_parallel_size=$PP 
    model.max_position_embeddings=$SEQ_LENGTH 
    model.encoder_seq_length=$SEQ_LENGTH 
    model.hidden_size=$HS 
    model.ffn_hidden_size=$FFN_HS 
    model.num_layers=$N_LAYERS 
    model.num_attention_heads=$N_AH 
    model.init_method_std=$INIT_METHOD_STD 
    model.hidden_dropout=0 
    model.layernorm_epsilon=$LAYERNORM_EPSILON 
    model.data.data_prefix=[1.0,$DATASET_PATH]
    model.data.num_workers=1 
    model.data.seq_length=$SEQ_LENGTH 
    model.optim.name=$OPTIM_NAME 
    model.optim.lr=3.0e-4 
    model.optim.betas=[0.9,0.95] 
    model.optim.weight_decay=0.1 
    model.optim.sched.name=CosineAnnealing 
    model.optim.sched.warmup_steps=$WARMUP_STEPS 
    model.optim.sched.constant_steps=0 
    model.optim.sched.min_lr=3.0e-5 
    model.optim.capturable=True 
    model.sequence_parallel=True  
    model.activations_checkpoint_granularity=full 
    model.activations_checkpoint_method=uniform 
    model.activations_checkpoint_num_layers=1 
    +model.save_xser=True
    exp_manager.create_tensorboard_logger=$CREATE_TB_LOGGER 
    exp_manager.resume_if_exists=False 
    exp_manager.resume_ignore_no_checkpoint=False 
    exp_manager.create_checkpoint_callback=$CHECKPOINT_CALLBACK 
    exp_manager.explicit_log_dir=$LOGS_DIR 
    +exp_manager.checkpoint_callback_params.train_time_interval=36000 
    model.use_cpu_initialization=True"
  - echo DISTRIBUTED_ARGS=$DISTRIBUTED_ARGS
  - echo "#!/bin/bash" >  compile.sh
  - echo export NEURON_CC_FLAGS=\"--model-type transformer --distribution-strategy=nemo --enable-mixed-precision-accumulation --cache_dir=$TMP_CACHE_DIR\" >> ./compile.sh
  - echo "torchrun $DISTRIBUTED_ARGS megatron_gpt_pretraining.py $LLAMA2_ARGS  2>&1 | tee $OUTPUT_LOG"  >> compile.sh 
  - chmod u+x ./compile.sh
post_script:
  - cp -r $TMP_CACHE_DIR/* $CACHE_DIR
train:
  env:
    - name: HOME
      value: /tmp
    - name: MODEL_PATH
      value: /fsx/pretrained-models/meta-llama/Llama-2-7b-hf
    - name: LOG_ROOT
      value: /efs/home/{{ .Release.Name }}/logs
    - name: DATA_ROOT
      value: /fsx/home/{{ .Release.Name }}/datasets
    - name: CACHE_ROOT
      value: /efs/home/{{ .Release.Name }}/cache
    - name: CCOM_SOCKET_IFNAME
      value: "eth0"
    - name: FI_EFA_USE_DEVICE_RDMA
      value: "1"
    - name: FI_PROVIDER
      value: "efa"
    - name: FI_EFA_FORK_SAFE
      value: "1"
    - name: NEURON_RT_STOCHASTIC_ROUNDING_EN
      value: "1"
    - name: NEURON_RT_ASYNC_EXEC_MAX_INFLIGHT_REQUESTS
      value: "5"
    - name: NEURON_TRANSFER_WITH_STATIC_RING_OPS
      value: ""
    - name: "NEURON_RT_EXEC_TIMEOUT"
      value: "10"
    - name: MALLOC_ARENA_MAX
      value: "128"
    - name: HYDRA_FULL_ERROR
      value: "1"
    - name: BUCKET_CAP_MB
      value: "1024"
    - name: TF_NUM_INTEROP_THREADS
      value: "1024"
    - name: XLA_THREAD_POOL_SIZE
      value: "4"
    - name: XLA_IO_THREAD_POOL_SIZE
      value: "4"
    - name: XLA_USE_BF16
      value: "1"
    - name: CREATE_TB_LOGGER
      value: "False"
    - name: CHECKPOINT_CALLBACK
      value: "False"
    - name: OPTIM_NAME
      value: "adamw"
    - name: megatron_amp_O2
      value: "false"
    
  command:
    -  neuron_parallel_compile
  args:
    - './compile.sh'
    - '2>&1 | tee $LOGS_DIR/neuron_parallel_compile.log'
